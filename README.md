# Theory-Code (TC) Notebooks

**Note**: *Github sometimes requires a little encouragement to render jupyter notebooks, presumably when there's high load on their servers. For a clean html version of each of these notebooks, I encourage you to visit [yashd.azurewebsites.net/TCBooks](http://yashd.azurewebsites.net/TCBooks).*

## Introduction

This repository is a collection of notebooks with explanations of topics, including both theory and code, from several fields, including signal processing, machine learning and information theory, which may be considerd to fall under the overall banner of data analytics. These are topics that I have found interesting, important or particularly difficult to master.

## Origin

The first notebooks in this repository grew from my exploration of specific topics that I found particularly interesting, and befuddling, because of the myriad ways in which these topics could be approached. In an effort to unscramble them for myself, I began to document my understanding from near first principles as well as implement them in code. I soon realised that this was a particularly effective approach to mastering a topic and began doing so for other complex/interesting topics that I encountered.

## Purpose

The purpose of these notebooks is to break down chosen topics to near first principles in a manner that I would have liked these topics explained to me when I first encountered them. My hope is that they will serve as a friendly and thorough introduction to these topics for anyone with a knowledge of high school mathematics seeking both theory and implementation and as a ready reference material for me when I revisit any of this topics.

## Index

### Theory
1. [Power Spectral Density - Theory](Power%20Spectral%20Density%20-%20Theory.ipynb)
    1. Energy and Power
    2. Autocorrelation
    3. Einstein-Wiener-Khintchine Theorem
    4. Motivation
    5. Parseval's Relation and Periodogram
    6. Further Reading
3. [Maximum Likelihood - Theory](Maximum%20Likelihood%20-%20Theory.ipynb)
    1. Shannon Entropy
    2. Measure of Information
    3. Cross-Entropy
    4. Kullback-Leibler Divergence
    5. Maximum Likelihood
    6. Connection to Entropy
    7. Fisher Information
    8. Cramer-Rao Inequality
    9. Further Reading

### Code

1. [Machine Learning - Topics (Classification and Probability Density Estimation)](Machine%20Learning%20I.ipynb) *(Stand-alone book)*
2. [Power Spectral Density - Code](Power%20Spectral%20Density%20-%20Code.ipynb) *(Sections mirror the content in Theory)*
4. [Maximum Likelihood - Code](Maximum%20Likelihood%20-%20Code.ipynb) *(Sections mirror the content in Theory)*
